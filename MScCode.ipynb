{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MScCode",
      "provenance": [],
      "collapsed_sections": [
        "8jLxiAwpHUrt"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/michelleaeh/ADissertation/blob/master/MScCode.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dcws6GC7s8aT",
        "colab_type": "text"
      },
      "source": [
        "**Project:** MSc in Robotics and Intelligent Systems Dissertation\n",
        "\n",
        "**Author:** Michelle Alejandra Espinosa Hernandez\n",
        "\n",
        "**Student registration number:** 1900964\n",
        "\n",
        "**Student PRID:** ESPIN62803\n",
        "\n",
        "**Date:** September 2020 \n",
        "\n",
        "**Purpose:** Obtain classification accuracy among different types of sensors and different data processing steps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8jLxiAwpHUrt",
        "colab_type": "text"
      },
      "source": [
        "# **Data description**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mH79ogCWrzbt",
        "colab_type": "text"
      },
      "source": [
        "**Myo armband dataset from https://data.mendeley.com/datasets/wgswcr8z24/2**\n",
        "\n",
        "\n",
        "The dataset consits of .csv files collected from two Myo armbands. The format of the files are [word_name]_[id]. The ‘word_name’ is the English translation of the American Sign Language word used and the ‘id’ is a unique identifier. The .zip for each of the above links has sub-folders for each User.\n",
        "\n",
        "Each file has 50 columns. They represent a sub-sampled data collection from two Myo devices worn on left and right hands of the signer. The first column is the ‘Counter’ that goes from 1 to 50.\n",
        "\n",
        "The following columns are of the format: [Sensor][pod/direction][left/right]. For instance the EMG reading for the first EMG pod (out of 8) on the left hand would be called EMG0R and the accelerometer reading for the Z axis on the left hand would be called: AXL\n",
        "\n",
        "If you use this dataset please cite the following papers:\n",
        "\n",
        "@inproceedings{paudyal2016sceptre,\n",
        "title={Sceptre: a pervasive, non-invasive, and programmable gesture recognition technology},\n",
        "author={Paudyal, Prajwal and Banerjee, Ayan and Gupta, Sandeep KS},\n",
        "booktitle={Proceedings of the 21st International Conference on Intelligent User Interfaces},\n",
        "pages={282--293},\n",
        "year={2016},\n",
        "organization={ACM}\n",
        "}\n",
        "\n",
        "@inproceedings{paudyal2017dyfav,\n",
        "title={Dyfav: Dynamic feature selection and voting for real-time recognition of fingerspelled alphabet using wearables},\n",
        "author={Paudyal, Prajwal and Lee, Junghyo and Banerjee, Ayan and Gupta, Sandeep KS},\n",
        "booktitle={Proceedings of the 22nd International Conference on Intelligent User Interfaces},\n",
        "pages={457--467},\n",
        "year={2017},\n",
        "organization={ACM}\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHNKWJHfhpMy",
        "colab_type": "text"
      },
      "source": [
        "**Frequency:**\n",
        "\n",
        "50Hz sampling rate\n",
        "\n",
        "**Words:**\n",
        "\n",
        "*36 total words*\n",
        "\n",
        "allmorning, bird, blue, cantsleep, cat, colrunnynose, continuouslyforanhour, cost, day, dollar, everymorning, everynight, gold, goodnight, happy, headache, home, horse, hot, hurt, itching, large, mom, monthly, notfeelgood, orange, pizza, please, shirt, soreness, swelling, takeliquidmedicine, thatsterrible, tired, upsetstomach, wash\n",
        "\n",
        "\n",
        "**Filenames:**\n",
        "\n",
        "*849 total files*\n",
        "\n",
        "(word)_(user#)(try#)\n",
        "\n",
        "\n",
        "**Columns of files:**\n",
        "\n",
        "Counter  (1 -> 50)\n",
        "\n",
        "EMG0L -> EMG7L  (EMG sensor readings)\n",
        "\n",
        "AXL, AYL, AZL  (accelerometer readings)\n",
        "\n",
        "GXL, GYL, GZL  (gyroscope readings)\n",
        "\n",
        "ORL, OPL, OYL  (magnetometer readings?)\n",
        "\n",
        "EMG0R -> EMG7R  (EMG sensor readings)\n",
        "\n",
        "AXR, AYR, AZR  (accelerometer readings)\n",
        "\n",
        "GXR, GYR, GZR  (gyroscope readings)\n",
        "\n",
        "ORR, OPR, OYR  (magnetometer readings?)\n",
        "\n",
        "features=['EMG0L', 'EMG1L', 'EMG2L', 'EMG3L', 'EMG4L', 'EMG5L', 'EMG6L', 'EMG7L', 'AXL', 'AYL', 'AZL', 'GXL', 'GYL', 'GZL', 'ORL', 'OPL', 'OYL', 'EMG0R', 'EMG1R', 'EMG2R', 'EMG3R', 'EMG4R', 'EMG5R', 'EMG6R', 'EMG7R', 'AXR', 'AYR', 'AZR', 'GXR', 'GYR', 'GZR', 'ORR', 'OPR', 'OYR']\n",
        "\n",
        "\n",
        "**Size of files:**\n",
        "\n",
        "All files are 50 rows x 35 columns except continuouslyforanhour_22.csv, headache_52.csv, home_61.csv, and mom_82.csv which are 101 rows x 35 columns\n",
        "\n",
        "**Steps:**\n",
        "\n",
        "1. Combine files\n",
        "2. Normalize or standardize matrix\n",
        "3. Apply Butterworth\n",
        "4. Apply PCA\n",
        "5. Input to SVM\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gca7rp-1Gimq",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "# **1. Preparation of data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oXI1GgkfFdai",
        "colab_type": "text"
      },
      "source": [
        "**1.1. Start up and initialization of variables**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TnTycFtrpHd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os.path\n",
        "import pandas as pd\n",
        "import scipy as sp\n",
        "import time\n",
        "import warnings\n",
        "\n",
        "from collections import Counter\n",
        "from google.colab import files\n",
        "from mpl_toolkits import mplot3d\n",
        "from scipy import signal\n",
        "from scipy.io import loadmat\n",
        "from sklearn import metrics\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import classification_report, plot_confusion_matrix\n",
        "from sklearn.model_selection import cross_val_score, GridSearchCV, KFold, train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from zipfile import ZipFile\n",
        "\n",
        "# Start timer\n",
        "starttime = time.time()\n",
        "\n",
        "# Eliminate warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Extract all files from zip\n",
        "with ZipFile(\"/content/2MyoASL.zip\", 'r') as zip:\n",
        "  zip.extractall()\n",
        "\n",
        "# Division of sensors\n",
        "emg=['EMG0L', 'EMG1L', 'EMG2L', 'EMG3L', 'EMG4L', 'EMG5L', 'EMG6L', 'EMG7L', \n",
        "     'EMG0R', 'EMG1R', 'EMG2R', 'EMG3R', 'EMG4R', 'EMG5R', 'EMG6R', 'EMG7R']\n",
        "acc=['AXL', 'AYL', 'AZL', 'AXR', 'AYR', 'AZR']\n",
        "gyro=['GXL', 'GYL', 'GZL', 'GXR', 'GYR', 'GZR']\n",
        "ori=['ORL', 'OPL', 'OYL', 'ORR', 'OPR', 'OYR']\n",
        "colnames=emg[:8]+acc[:3]+gyro[:3]+ori[:3]+emg[8:]+acc[3:]+gyro[3:]+ori[3:]\n",
        "\n",
        "# Words\n",
        "words=['allmorning', 'bird', 'blue', 'cantsleep', 'cat', 'coldrunnynose', 'continuouslyforanhour', 'cost', 'day', \n",
        "       'dollar', 'everymorning', 'everynight', 'gold', 'goodnight', 'happy', 'headache', 'home', 'horse', 'hot', \n",
        "       'hurt', 'itching', 'large', 'mom', 'monthly', 'notfeelgood', 'orange', 'pizza', 'please', 'shirt', \n",
        "       'soreness', 'swelling', 'takeliquidmedicine', 'thatsterrible', 'tired', 'upsetstomach', 'wash']\n",
        "\n",
        "# Generation of matrices\n",
        "### Combinations of sensors (E=emg=3, A=acc=5, G=gyro=7, O=ori=11)\n",
        "comb=['E', 'A', 'G', 'O', 'EA', 'EG', 'EO', 'AG', 'AO', 'GO', 'EAG', 'EAO', 'EGO', 'AGO', 'EAGO'] \n",
        "products=[3, 5, 7, 11, 15, 21, 33, 35, 55, 77, 105, 165, 231, 385, 1155] \n",
        "### Combinations of steps (N=Normalization=3, S=Standardization=5, B=Butterworth=7, P=PCA=11, V=SVM=13)\n",
        "nsteps=['V', 'NV', 'SV', 'BV', 'PV', 'NBV', 'NPV', 'SBV', 'SPV', 'BPV', 'NBPV', 'SBPV'] \n",
        "steps=[13, 39, 65, 91, 143, 273, 429, 455, 715, 1001, 3003, 5005] \n",
        "### Placeholders\n",
        "fresults=np.zeros((len(steps),len(products)))\n",
        "params=np.zeros((len(steps),len(products)))\n",
        "headers=np.empty(1701, dtype=object)\n",
        "lengths=np.zeros(849, dtype=int)\n",
        "repsum=np.zeros(37,dtype=int)\n",
        "reps=np.zeros(36,dtype=int)\n",
        "features=np.zeros(15)\n",
        "target=np.zeros(15)\n",
        "fn=np.arange(1701)\n",
        "matrix=np.zeros(1)\n",
        "stand=[]\n",
        "norm=[]\n",
        "\n",
        "# Initiation of counters\n",
        "wordnum=-1\n",
        "counter=-1\n",
        "rownum=-1\n",
        "start=0\n",
        "num=0\n",
        "n=0"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gAKRziACFoe0",
        "colab_type": "text"
      },
      "source": [
        "**1.2. Combine all files**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQFtofv7yG7G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "8fb0cf99-41c6-4bdd-aa15-2aa90fa81307"
      },
      "source": [
        "for w in words:\n",
        "  repcount=0\n",
        "  wordnum+=1\n",
        "  for i in range (10, 120):\n",
        "    path='/content/2MyoASL/' + w + '_' + str(i) + '.csv'\n",
        "    if os.path.exists(path)==True:\n",
        "      counter+=1\n",
        "      repcount+=1\n",
        "      trial=pd.read_csv(path)\n",
        "      trial.reset_index(drop=True)\n",
        "      \n",
        "      # Assign word number to each row and make data horizontal\n",
        "      row=np.zeros(1)\n",
        "      for t in range(35):\n",
        "        if t==0:\n",
        "          row[0]=wordnum\n",
        "        else:\n",
        "          sensor=trial.iloc[0:50,t].values\n",
        "          sensor.reshape([1,50])\n",
        "          row=np.concatenate((row, sensor))\n",
        "      prev=row\n",
        "      \n",
        "      # Combine all trials\n",
        "      if counter==0:\n",
        "        matrix=prev\n",
        "      else:\n",
        "        matrix=np.concatenate([matrix,prev])\n",
        "\n",
        "  reps[wordnum]=repcount\n",
        "  if wordnum>0:\n",
        "    repsum[wordnum]=reps[wordnum-1]+repsum[wordnum-1]\n",
        "    repsum[36]=849\n",
        "\n",
        "# Create header name array\n",
        "headers[0]='Word'\n",
        "for c in colnames:\n",
        "  for t in range(50):\n",
        "    num+=1\n",
        "    headers[num]=c\n",
        "\n",
        "# Give format to final matrix \n",
        "matrix=matrix.reshape([849,1701])\n",
        "matrix=pd.DataFrame(matrix, columns=headers)\n",
        "matrix=pd.concat([matrix['Word'],matrix[emg],matrix[acc],matrix[gyro],matrix[ori]],axis=1)\n",
        "exec(\"matrix.to_csv(path_or_buf='/content/complete_matrix_'+str(9)+'.csv')\")\n",
        "print('Reps of each word:',reps)\n",
        "print('Cummulative reps:',repsum)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reps of each word: [19 24 32 20 24 20 19 31 24 29 20 21 23 33 34 18 27 24 35 19 17 34 30 19\n",
            " 22 21 23 27 27  4 20 19 20 20 21 29]\n",
            "Cummulative reps: [  0  19  43  75  95 119 139 158 189 213 242 262 283 306 339 373 391 418\n",
            " 442 477 496 513 547 577 596 618 639 662 689 716 720 740 759 779 799 820\n",
            " 849]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CaKAX2XvGL3O",
        "colab_type": "text"
      },
      "source": [
        "**1.3. Calculate mean and standard deviation of each sensor and each file**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oaytNKUWGo7E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 691
        },
        "outputId": "0ae9fa66-cdc5-4c63-a9db-b80e1e42728b"
      },
      "source": [
        "# Average and standard deviation of each sensor in each file\n",
        "for s in colnames:\n",
        "  avg=matrix[s].mean(axis=1)\n",
        "  sd=matrix[s].std(axis=1)\n",
        "  sensor=pd.concat([avg.rename(s+': Mean_'),sd.rename('St. dev.')], axis=1)\n",
        "  if s=='EMG0L':\n",
        "    asd=sensor\n",
        "  else:\n",
        "    asd=pd.concat([asd, sensor], axis=1)\n",
        "print('Average and standard deviation of each sensor per file')\n",
        "print(asd)\n",
        "\n",
        "# Average and standard deviation of each file\n",
        "avg=matrix.mean(axis=1)\n",
        "sd=matrix.std(axis=1)\n",
        "print('Average and standard deviation of each file')\n",
        "pd.concat([avg.rename('Mean'),sd.rename('St. dev.')], axis=1)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average and standard deviation of each sensor per file\n",
            "     EMG0L: Mean_   St. dev.  EMG1L: Mean_  ...   St. dev.  OYR: Mean_   St. dev.\n",
            "0           -2.32   8.664825         -0.80  ...  28.427609       86.70  10.529356\n",
            "1           -1.80   9.544739         -4.08  ...  27.821010       85.68   6.579002\n",
            "2           -3.16  13.085839         -2.32  ...  30.345736       91.88  17.358924\n",
            "3           -0.82  10.123099         -3.16  ...  29.645002       88.46  12.969682\n",
            "4           -0.50   6.516071          2.76  ...  13.237239      116.58  18.099600\n",
            "..            ...        ...           ...  ...        ...         ...        ...\n",
            "844          0.56   7.754288          0.22  ...  17.236281      104.76   7.528341\n",
            "845         -1.74   6.520955         -1.20  ...  21.772891       69.66  85.251036\n",
            "846          1.02   7.731436          0.46  ...  22.707735       56.76  79.408415\n",
            "847          0.06   5.582078          2.36  ...  23.650422       71.62  84.238701\n",
            "848         -2.22   7.434860         -1.62  ...  25.101622       58.52  79.668763\n",
            "\n",
            "[849 rows x 68 columns]\n",
            "Average and standard deviation of each file\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Mean</th>\n",
              "      <th>St. dev.</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>15.256437</td>\n",
              "      <td>46.545832</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>14.220110</td>\n",
              "      <td>47.316822</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>15.441784</td>\n",
              "      <td>45.614456</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>13.651092</td>\n",
              "      <td>47.038916</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>15.063294</td>\n",
              "      <td>49.105612</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>844</th>\n",
              "      <td>13.167964</td>\n",
              "      <td>41.642351</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>845</th>\n",
              "      <td>13.815314</td>\n",
              "      <td>42.880121</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>846</th>\n",
              "      <td>12.970618</td>\n",
              "      <td>42.725653</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>847</th>\n",
              "      <td>13.852317</td>\n",
              "      <td>43.758631</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>848</th>\n",
              "      <td>13.144035</td>\n",
              "      <td>44.761750</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>849 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          Mean   St. dev.\n",
              "0    15.256437  46.545832\n",
              "1    14.220110  47.316822\n",
              "2    15.441784  45.614456\n",
              "3    13.651092  47.038916\n",
              "4    15.063294  49.105612\n",
              "..         ...        ...\n",
              "844  13.167964  41.642351\n",
              "845  13.815314  42.880121\n",
              "846  12.970618  42.725653\n",
              "847  13.852317  43.758631\n",
              "848  13.144035  44.761750\n",
              "\n",
              "[849 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5aFRMDnxG3yZ",
        "colab_type": "text"
      },
      "source": [
        "# **Variable definition**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oweA9Tcyf_I2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "numreps=9      # Number of repetitions per word\n",
        "num_trials=10  # Number of runs of cross validation"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1w9SOqkf5vE",
        "colab_type": "text"
      },
      "source": [
        "# **2. Data adjustement**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "em1GhMP586_j",
        "colab_type": "text"
      },
      "source": [
        "**2.1. Establish equal number of repetitions per word**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLze9It2KrBp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "825fe8ef-1a0c-41d5-f5c4-2237dc7af01d"
      },
      "source": [
        "for i in range(len(reps)-1,-1,-1):\n",
        "  tl=sd.iloc[repsum[i]:repsum[i+1]]\n",
        "  u=repsum[i+1]-1\n",
        "  if reps[i]<numreps:\n",
        "    for r in range(len(matrix)-1,-1,-1):\n",
        "      if int(matrix.iloc[r]['Word'])==i:\n",
        "        matrix=matrix.drop(r)\n",
        "  elif reps[i]>numreps:\n",
        "    while reps[i]>numreps:\n",
        "      if tl[u]==tl.max():\n",
        "        tl[u]=0\n",
        "        matrix=matrix.drop(u)\n",
        "        reps[i]=reps[i]-1\n",
        "        u=repsum[i+1]-1\n",
        "      else:\n",
        "        u-=1\n",
        "\n",
        "print(matrix)\n",
        "print('Repetitions per word:',reps)\n",
        "exec(\"matrix.to_csv(path_or_buf='/content/matrix_'+str(numreps)+'.csv')\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     Word  EMG0L  EMG0L  EMG0L  EMG0L  ...    OYR    OYR    OYR    OYR    OYR\n",
            "2     0.0    0.0    0.0   -8.0   -1.0  ...   84.0   84.0   84.0   84.0   84.0\n",
            "5     0.0    0.0    0.0   -2.0    0.0  ...  133.0  131.0  129.0  125.0  119.0\n",
            "8     0.0    0.0    0.0   -6.0   -3.0  ...   21.0   20.0   20.0   20.0   20.0\n",
            "9     0.0    0.0    0.0  -22.0   -1.0  ...   22.0   22.0   22.0   22.0   22.0\n",
            "10    0.0    0.0    0.0   -2.0    0.0  ...   23.0   23.0   23.0   23.0   23.0\n",
            "..    ...    ...    ...    ...    ...  ...    ...    ...    ...    ...    ...\n",
            "833  35.0    0.0    0.0   -3.0    2.0  ...   63.0   63.0   63.0   63.0   63.0\n",
            "834  35.0    0.0    0.0   -4.0    4.0  ...   64.0   63.0   63.0   63.0   63.0\n",
            "835  35.0    0.0    0.0   23.0    1.0  ...   68.0   66.0   65.0   63.0   63.0\n",
            "836  35.0    0.0    0.0   -4.0   -8.0  ...   62.0   62.0   62.0   62.0   62.0\n",
            "841  35.0    0.0    0.0   -1.0   -6.0  ...  102.0  101.0   99.0   97.0   95.0\n",
            "\n",
            "[315 rows x 1701 columns]\n",
            "Repetitions per word: [9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 4 9 9 9 9 9 9]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rv_VaSCnHJYz",
        "colab_type": "text"
      },
      "source": [
        "**2.2. Create sensor combinatory matrices: unaltered, normalized, and standardized**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7Ib41KW5f32",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d2bbc81e-0a9c-4c50-9f3e-c99c77a414d3"
      },
      "source": [
        "# Eliminate unnecessary columns to create combinatory matrices\n",
        "for v in products:\n",
        "  m=matrix.copy()\n",
        "  if v%3!=0:\n",
        "    m=m.drop(emg,1)\n",
        "  if v%5!=0:\n",
        "    m=m.drop(acc,1)\n",
        "  if v%7!=0:\n",
        "    m=m.drop(gyro,1)\n",
        "  if v%11!=0:\n",
        "    m=m.drop(ori,1)\n",
        "  \n",
        "  # Separate features from target values\n",
        "  x = m.iloc[:, m.columns!='Word']   # Features\n",
        "\n",
        "  # Create column of words instead of number\n",
        "  wordcol=np.empty(len(m), dtype=object)\n",
        "  z=0\n",
        "  wcol=[int(i) for i in m['Word'].values]\n",
        "  for f in wcol:\n",
        "    wordcol[z]=words[f]\n",
        "    z+=1\n",
        "  wordcol=np.asmatrix(wordcol)\n",
        "  regular=np.concatenate((np.transpose(wordcol),np.copy(m.iloc[:,1:])),axis=1)\n",
        "  products[n]=pd.DataFrame(regular,columns=m.columns).dropna(axis=1)\n",
        " \n",
        "  ## Normalize features so that each column is between 0 and 1\n",
        "  norm_matrix=(m-m.min())/(m.max()-m.min())\n",
        "  norm_matrix=np.concatenate((np.transpose(wordcol),norm_matrix.iloc[:,1:]),axis=1)\n",
        "  norm_matrix=pd.DataFrame(norm_matrix,columns=m.columns).dropna(axis=1)\n",
        "  norm.append(norm_matrix)\n",
        "  \n",
        "  ## Standardize features with mean=0 and deviation=1\n",
        "  standardized_matrix=StandardScaler().fit_transform(x)\n",
        "  standardized_matrix=np.concatenate((np.transpose(wordcol),standardized_matrix),axis=1)\n",
        "  standardized_matrix=pd.DataFrame(standardized_matrix,columns=m.columns).dropna(axis=1)\n",
        "  stand.append(standardized_matrix)\n",
        "  n+=1"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     Word  EMG0L  EMG0L  EMG0L  EMG0L  ...    OYR    OYR    OYR    OYR    OYR\n",
            "2     0.0    0.0    0.0   -8.0   -1.0  ...   84.0   84.0   84.0   84.0   84.0\n",
            "5     0.0    0.0    0.0   -2.0    0.0  ...  133.0  131.0  129.0  125.0  119.0\n",
            "8     0.0    0.0    0.0   -6.0   -3.0  ...   21.0   20.0   20.0   20.0   20.0\n",
            "9     0.0    0.0    0.0  -22.0   -1.0  ...   22.0   22.0   22.0   22.0   22.0\n",
            "10    0.0    0.0    0.0   -2.0    0.0  ...   23.0   23.0   23.0   23.0   23.0\n",
            "..    ...    ...    ...    ...    ...  ...    ...    ...    ...    ...    ...\n",
            "833  35.0    0.0    0.0   -3.0    2.0  ...   63.0   63.0   63.0   63.0   63.0\n",
            "834  35.0    0.0    0.0   -4.0    4.0  ...   64.0   63.0   63.0   63.0   63.0\n",
            "835  35.0    0.0    0.0   23.0    1.0  ...   68.0   66.0   65.0   63.0   63.0\n",
            "836  35.0    0.0    0.0   -4.0   -8.0  ...   62.0   62.0   62.0   62.0   62.0\n",
            "841  35.0    0.0    0.0   -1.0   -6.0  ...  102.0  101.0   99.0   97.0   95.0\n",
            "\n",
            "[315 rows x 1701 columns]\n",
            "           Word EMG0L EMG0L EMG0L EMG0L EMG0L  ...  OYR  OYR  OYR  OYR  OYR  OYR\n",
            "0    allmorning     0     0    -8    -1    11  ...   84   84   84   84   84   84\n",
            "1    allmorning     0     0    -2     0    -2  ...  133  133  131  129  125  119\n",
            "2    allmorning     0     0    -6    -3    13  ...   21   21   20   20   20   20\n",
            "3    allmorning     0     0   -22    -1    -2  ...   22   22   22   22   22   22\n",
            "4    allmorning     0     0    -2     0     0  ...   24   23   23   23   23   23\n",
            "..          ...   ...   ...   ...   ...   ...  ...  ...  ...  ...  ...  ...  ...\n",
            "310        wash     0     0    -3     2    -1  ...   63   63   63   63   63   63\n",
            "311        wash     0     0    -4     4    -3  ...   64   64   63   63   63   63\n",
            "312        wash     0     0    23     1   -12  ...   71   68   66   65   63   63\n",
            "313        wash     0     0    -4    -8     2  ...   62   62   62   62   62   62\n",
            "314        wash     0     0    -1    -6     1  ...  104  102  101   99   97   95\n",
            "\n",
            "[315 rows x 1701 columns]\n",
            "[           Word EMG0L EMG0L EMG0L EMG0L  ... EMG7R EMG7R EMG7R EMG7R EMG7R\n",
            "0    allmorning     0     0    -8    -1  ...     2    -2    -1     2    14\n",
            "1    allmorning     0     0    -2     0  ...    -1    -1     1     1    -1\n",
            "2    allmorning     0     0    -6    -3  ...    -1     0    -3     1    -2\n",
            "3    allmorning     0     0   -22    -1  ...     0     0    -1    -2     2\n",
            "4    allmorning     0     0    -2     0  ...    -1     0     0    -1    -1\n",
            "..          ...   ...   ...   ...   ...  ...   ...   ...   ...   ...   ...\n",
            "310        wash     0     0    -3     2  ...    -5     0     0     1    -2\n",
            "311        wash     0     0    -4     4  ...     9     4     6     1    -7\n",
            "312        wash     0     0    23     1  ...     1     1    -2    -3    -8\n",
            "313        wash     0     0    -4    -8  ...     0    -9     1   -15     2\n",
            "314        wash     0     0    -1    -6  ...     0    -2     1     4   -15\n",
            "\n",
            "[315 rows x 801 columns],            Word          AXL        AXL  ...       AZR       AZR       AZR\n",
            "0    allmorning      0.09375   0.106934  ...   1.04688   1.00342   1.01514\n",
            "1    allmorning  0.000488281  0.0913086  ...  0.978027  0.941406  0.851074\n",
            "2    allmorning    -0.146484  -0.162598  ...  0.964844   0.90625  0.933594\n",
            "3    allmorning    -0.245605  -0.226074  ...  0.991699  0.963867  0.958984\n",
            "4    allmorning     0.314941   0.170898  ...  0.913086  0.965332   0.87207\n",
            "..          ...          ...        ...  ...       ...       ...       ...\n",
            "310        wash     0.230957    0.18457  ...   1.03271    1.0249  0.977051\n",
            "311        wash     -0.24707  -0.220215  ...   1.00781  0.926758    1.0459\n",
            "312        wash      0.30127   0.314453  ...  0.976074  0.988281   1.18457\n",
            "313        wash     0.275391   0.275391  ...   1.01807   1.02295   1.02246\n",
            "314        wash    -0.409668  -0.407227  ...  0.857422  0.895996  0.894531\n",
            "\n",
            "[315 rows x 301 columns],            Word      GXL      GXL      GXL  ...      GZR      GZR      GZR      GZR\n",
            "0    allmorning  35.9375    43.25   26.125  ...    2.875   2.8125   0.9375   0.5625\n",
            "1    allmorning      -89  -81.875  -54.375  ... -62.9375 -97.6875 -146.062 -184.562\n",
            "2    allmorning    0.375  -0.5625    5.125  ...  -16.875  -10.625    1.125   2.8125\n",
            "3    allmorning   -6.375   7.6875  -17.375  ...   6.3125     1.25  -2.4375   -2.125\n",
            "4    allmorning -126.812 -138.125   20.875  ...  -4.8125     2.75    -0.75   4.8125\n",
            "..          ...      ...      ...      ...  ...      ...      ...      ...      ...\n",
            "310        wash   -10.25 -20.5625 -14.3125  ...  -6.1875  -5.3125   -0.125    1.375\n",
            "311        wash    -0.25  -8.9375 -46.8125  ...   -14.75  -4.8125   -14.75   -1.625\n",
            "312        wash  -14.125  -9.8125 -18.4375  ...   -53.25  -52.625      -41      -13\n",
            "313        wash   50.375   50.375      0.5  ...       -4    -4.25   -1.375    1.125\n",
            "314        wash  -84.125   -51.75   -34.25  ...  -89.375 -118.875  -137.75 -125.125\n",
            "\n",
            "[315 rows x 301 columns],            Word  ORL  ORL  ORL  ORL  ORL  ...  OYR  OYR  OYR  OYR  OYR  OYR\n",
            "0    allmorning  101  102  104  104  104  ...   84   84   84   84   84   84\n",
            "1    allmorning   66   65   63   63   62  ...  133  133  131  129  125  119\n",
            "2    allmorning   92   92   91   91   90  ...   21   21   20   20   20   20\n",
            "3    allmorning   90   90   89   87   85  ...   22   22   22   22   22   22\n",
            "4    allmorning   86   85   85   88   89  ...   24   23   23   23   23   23\n",
            "..          ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...\n",
            "310        wash   66   66   66   67   68  ...   63   63   63   63   63   63\n",
            "311        wash   72   72   71   69   69  ...   64   64   63   63   63   63\n",
            "312        wash   65   65   66   67   68  ...   71   68   66   65   63   63\n",
            "313        wash   73   73   74   74   72  ...   62   62   62   62   62   62\n",
            "314        wash   64   63   61   60   59  ...  104  102  101   99   97   95\n",
            "\n",
            "[315 rows x 301 columns],            Word EMG0L EMG0L EMG0L  ...       AZR       AZR       AZR       AZR\n",
            "0    allmorning     0     0    -8  ...   1.02637   1.04688   1.00342   1.01514\n",
            "1    allmorning     0     0    -2  ...  0.948242  0.978027  0.941406  0.851074\n",
            "2    allmorning     0     0    -6  ...  0.897949  0.964844   0.90625  0.933594\n",
            "3    allmorning     0     0   -22  ...  0.940918  0.991699  0.963867  0.958984\n",
            "4    allmorning     0     0    -2  ...  0.897949  0.913086  0.965332   0.87207\n",
            "..          ...   ...   ...   ...  ...       ...       ...       ...       ...\n",
            "310        wash     0     0    -3  ...  0.976074   1.03271    1.0249  0.977051\n",
            "311        wash     0     0    -4  ...  0.988281   1.00781  0.926758    1.0459\n",
            "312        wash     0     0    23  ...  0.990723  0.976074  0.988281   1.18457\n",
            "313        wash     0     0    -4  ...   1.03516   1.01807   1.02295   1.02246\n",
            "314        wash     0     0    -1  ...  0.878418  0.857422  0.895996  0.894531\n",
            "\n",
            "[315 rows x 1101 columns],            Word EMG0L EMG0L EMG0L  ...      GZR      GZR      GZR      GZR\n",
            "0    allmorning     0     0    -8  ...    2.875   2.8125   0.9375   0.5625\n",
            "1    allmorning     0     0    -2  ... -62.9375 -97.6875 -146.062 -184.562\n",
            "2    allmorning     0     0    -6  ...  -16.875  -10.625    1.125   2.8125\n",
            "3    allmorning     0     0   -22  ...   6.3125     1.25  -2.4375   -2.125\n",
            "4    allmorning     0     0    -2  ...  -4.8125     2.75    -0.75   4.8125\n",
            "..          ...   ...   ...   ...  ...      ...      ...      ...      ...\n",
            "310        wash     0     0    -3  ...  -6.1875  -5.3125   -0.125    1.375\n",
            "311        wash     0     0    -4  ...   -14.75  -4.8125   -14.75   -1.625\n",
            "312        wash     0     0    23  ...   -53.25  -52.625      -41      -13\n",
            "313        wash     0     0    -4  ...       -4    -4.25   -1.375    1.125\n",
            "314        wash     0     0    -1  ...  -89.375 -118.875  -137.75 -125.125\n",
            "\n",
            "[315 rows x 1101 columns],            Word EMG0L EMG0L EMG0L EMG0L EMG0L  ...  OYR  OYR  OYR  OYR  OYR  OYR\n",
            "0    allmorning     0     0    -8    -1    11  ...   84   84   84   84   84   84\n",
            "1    allmorning     0     0    -2     0    -2  ...  133  133  131  129  125  119\n",
            "2    allmorning     0     0    -6    -3    13  ...   21   21   20   20   20   20\n",
            "3    allmorning     0     0   -22    -1    -2  ...   22   22   22   22   22   22\n",
            "4    allmorning     0     0    -2     0     0  ...   24   23   23   23   23   23\n",
            "..          ...   ...   ...   ...   ...   ...  ...  ...  ...  ...  ...  ...  ...\n",
            "310        wash     0     0    -3     2    -1  ...   63   63   63   63   63   63\n",
            "311        wash     0     0    -4     4    -3  ...   64   64   63   63   63   63\n",
            "312        wash     0     0    23     1   -12  ...   71   68   66   65   63   63\n",
            "313        wash     0     0    -4    -8     2  ...   62   62   62   62   62   62\n",
            "314        wash     0     0    -1    -6     1  ...  104  102  101   99   97   95\n",
            "\n",
            "[315 rows x 1101 columns],            Word          AXL        AXL  ...      GZR      GZR      GZR\n",
            "0    allmorning      0.09375   0.106934  ...   2.8125   0.9375   0.5625\n",
            "1    allmorning  0.000488281  0.0913086  ... -97.6875 -146.062 -184.562\n",
            "2    allmorning    -0.146484  -0.162598  ...  -10.625    1.125   2.8125\n",
            "3    allmorning    -0.245605  -0.226074  ...     1.25  -2.4375   -2.125\n",
            "4    allmorning     0.314941   0.170898  ...     2.75    -0.75   4.8125\n",
            "..          ...          ...        ...  ...      ...      ...      ...\n",
            "310        wash     0.230957    0.18457  ...  -5.3125   -0.125    1.375\n",
            "311        wash     -0.24707  -0.220215  ...  -4.8125   -14.75   -1.625\n",
            "312        wash      0.30127   0.314453  ...  -52.625      -41      -13\n",
            "313        wash     0.275391   0.275391  ...    -4.25   -1.375    1.125\n",
            "314        wash    -0.409668  -0.407227  ... -118.875  -137.75 -125.125\n",
            "\n",
            "[315 rows x 601 columns],            Word          AXL        AXL        AXL  ...  OYR  OYR  OYR  OYR\n",
            "0    allmorning      0.09375   0.106934   0.142578  ...   84   84   84   84\n",
            "1    allmorning  0.000488281  0.0913086   0.273438  ...  131  129  125  119\n",
            "2    allmorning    -0.146484  -0.162598  -0.203613  ...   20   20   20   20\n",
            "3    allmorning    -0.245605  -0.226074 -0.0908203  ...   22   22   22   22\n",
            "4    allmorning     0.314941   0.170898   0.319824  ...   23   23   23   23\n",
            "..          ...          ...        ...        ...  ...  ...  ...  ...  ...\n",
            "310        wash     0.230957    0.18457   0.134277  ...   63   63   63   63\n",
            "311        wash     -0.24707  -0.220215  -0.366699  ...   63   63   63   63\n",
            "312        wash      0.30127   0.314453   0.331055  ...   66   65   63   63\n",
            "313        wash     0.275391   0.275391   0.252441  ...   62   62   62   62\n",
            "314        wash    -0.409668  -0.407227  -0.226562  ...  101   99   97   95\n",
            "\n",
            "[315 rows x 601 columns],            Word      GXL      GXL      GXL      GXL  ...  OYR  OYR  OYR  OYR  OYR\n",
            "0    allmorning  35.9375    43.25   26.125    -14.5  ...   84   84   84   84   84\n",
            "1    allmorning      -89  -81.875  -54.375   -68.75  ...  133  131  129  125  119\n",
            "2    allmorning    0.375  -0.5625    5.125 -23.0625  ...   21   20   20   20   20\n",
            "3    allmorning   -6.375   7.6875  -17.375 -138.625  ...   22   22   22   22   22\n",
            "4    allmorning -126.812 -138.125   20.875   6.9375  ...   23   23   23   23   23\n",
            "..          ...      ...      ...      ...      ...  ...  ...  ...  ...  ...  ...\n",
            "310        wash   -10.25 -20.5625 -14.3125     9.75  ...   63   63   63   63   63\n",
            "311        wash    -0.25  -8.9375 -46.8125 -17.9375  ...   64   63   63   63   63\n",
            "312        wash  -14.125  -9.8125 -18.4375  -11.625  ...   68   66   65   63   63\n",
            "313        wash   50.375   50.375      0.5  -10.375  ...   62   62   62   62   62\n",
            "314        wash  -84.125   -51.75   -34.25      -26  ...  102  101   99   97   95\n",
            "\n",
            "[315 rows x 601 columns],            Word EMG0L EMG0L EMG0L  ...      GZR      GZR      GZR      GZR\n",
            "0    allmorning     0     0    -8  ...    2.875   2.8125   0.9375   0.5625\n",
            "1    allmorning     0     0    -2  ... -62.9375 -97.6875 -146.062 -184.562\n",
            "2    allmorning     0     0    -6  ...  -16.875  -10.625    1.125   2.8125\n",
            "3    allmorning     0     0   -22  ...   6.3125     1.25  -2.4375   -2.125\n",
            "4    allmorning     0     0    -2  ...  -4.8125     2.75    -0.75   4.8125\n",
            "..          ...   ...   ...   ...  ...      ...      ...      ...      ...\n",
            "310        wash     0     0    -3  ...  -6.1875  -5.3125   -0.125    1.375\n",
            "311        wash     0     0    -4  ...   -14.75  -4.8125   -14.75   -1.625\n",
            "312        wash     0     0    23  ...   -53.25  -52.625      -41      -13\n",
            "313        wash     0     0    -4  ...       -4    -4.25   -1.375    1.125\n",
            "314        wash     0     0    -1  ...  -89.375 -118.875  -137.75 -125.125\n",
            "\n",
            "[315 rows x 1401 columns],            Word EMG0L EMG0L EMG0L EMG0L EMG0L  ...  OYR  OYR  OYR  OYR  OYR  OYR\n",
            "0    allmorning     0     0    -8    -1    11  ...   84   84   84   84   84   84\n",
            "1    allmorning     0     0    -2     0    -2  ...  133  133  131  129  125  119\n",
            "2    allmorning     0     0    -6    -3    13  ...   21   21   20   20   20   20\n",
            "3    allmorning     0     0   -22    -1    -2  ...   22   22   22   22   22   22\n",
            "4    allmorning     0     0    -2     0     0  ...   24   23   23   23   23   23\n",
            "..          ...   ...   ...   ...   ...   ...  ...  ...  ...  ...  ...  ...  ...\n",
            "310        wash     0     0    -3     2    -1  ...   63   63   63   63   63   63\n",
            "311        wash     0     0    -4     4    -3  ...   64   64   63   63   63   63\n",
            "312        wash     0     0    23     1   -12  ...   71   68   66   65   63   63\n",
            "313        wash     0     0    -4    -8     2  ...   62   62   62   62   62   62\n",
            "314        wash     0     0    -1    -6     1  ...  104  102  101   99   97   95\n",
            "\n",
            "[315 rows x 1401 columns],            Word EMG0L EMG0L EMG0L EMG0L EMG0L  ...  OYR  OYR  OYR  OYR  OYR  OYR\n",
            "0    allmorning     0     0    -8    -1    11  ...   84   84   84   84   84   84\n",
            "1    allmorning     0     0    -2     0    -2  ...  133  133  131  129  125  119\n",
            "2    allmorning     0     0    -6    -3    13  ...   21   21   20   20   20   20\n",
            "3    allmorning     0     0   -22    -1    -2  ...   22   22   22   22   22   22\n",
            "4    allmorning     0     0    -2     0     0  ...   24   23   23   23   23   23\n",
            "..          ...   ...   ...   ...   ...   ...  ...  ...  ...  ...  ...  ...  ...\n",
            "310        wash     0     0    -3     2    -1  ...   63   63   63   63   63   63\n",
            "311        wash     0     0    -4     4    -3  ...   64   64   63   63   63   63\n",
            "312        wash     0     0    23     1   -12  ...   71   68   66   65   63   63\n",
            "313        wash     0     0    -4    -8     2  ...   62   62   62   62   62   62\n",
            "314        wash     0     0    -1    -6     1  ...  104  102  101   99   97   95\n",
            "\n",
            "[315 rows x 1401 columns],            Word          AXL        AXL        AXL  ...  OYR  OYR  OYR  OYR\n",
            "0    allmorning      0.09375   0.106934   0.142578  ...   84   84   84   84\n",
            "1    allmorning  0.000488281  0.0913086   0.273438  ...  131  129  125  119\n",
            "2    allmorning    -0.146484  -0.162598  -0.203613  ...   20   20   20   20\n",
            "3    allmorning    -0.245605  -0.226074 -0.0908203  ...   22   22   22   22\n",
            "4    allmorning     0.314941   0.170898   0.319824  ...   23   23   23   23\n",
            "..          ...          ...        ...        ...  ...  ...  ...  ...  ...\n",
            "310        wash     0.230957    0.18457   0.134277  ...   63   63   63   63\n",
            "311        wash     -0.24707  -0.220215  -0.366699  ...   63   63   63   63\n",
            "312        wash      0.30127   0.314453   0.331055  ...   66   65   63   63\n",
            "313        wash     0.275391   0.275391   0.252441  ...   62   62   62   62\n",
            "314        wash    -0.409668  -0.407227  -0.226562  ...  101   99   97   95\n",
            "\n",
            "[315 rows x 901 columns],            Word EMG0L EMG0L EMG0L EMG0L EMG0L  ...  OYR  OYR  OYR  OYR  OYR  OYR\n",
            "0    allmorning     0     0    -8    -1    11  ...   84   84   84   84   84   84\n",
            "1    allmorning     0     0    -2     0    -2  ...  133  133  131  129  125  119\n",
            "2    allmorning     0     0    -6    -3    13  ...   21   21   20   20   20   20\n",
            "3    allmorning     0     0   -22    -1    -2  ...   22   22   22   22   22   22\n",
            "4    allmorning     0     0    -2     0     0  ...   24   23   23   23   23   23\n",
            "..          ...   ...   ...   ...   ...   ...  ...  ...  ...  ...  ...  ...  ...\n",
            "310        wash     0     0    -3     2    -1  ...   63   63   63   63   63   63\n",
            "311        wash     0     0    -4     4    -3  ...   64   64   63   63   63   63\n",
            "312        wash     0     0    23     1   -12  ...   71   68   66   65   63   63\n",
            "313        wash     0     0    -4    -8     2  ...   62   62   62   62   62   62\n",
            "314        wash     0     0    -1    -6     1  ...  104  102  101   99   97   95\n",
            "\n",
            "[315 rows x 1701 columns]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJtV04hjOid6",
        "colab_type": "text"
      },
      "source": [
        "# **3. Definition of functions for steps**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQF9gp3gVloy",
        "colab_type": "text"
      },
      "source": [
        "**3.1. Split data into train and test sets**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfHNiVxNVvK4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def datasplit(inmatrix_p):\n",
        "    x = inmatrix_p.iloc[:, inmatrix_p.columns!='Word']   # Features\n",
        "    y = inmatrix_p.loc[:,'Word']                         # Target\n",
        "    x_train_p, x_test_p, y_train_p, y_test_p = train_test_split(x, y, test_size=0.3)\n",
        "    return x_train_p, x_test_p, y_train_p, y_test_p"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGLs1pC8Vg15",
        "colab_type": "text"
      },
      "source": [
        "**3.2. Butterworth**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJjGC_1Q5r03",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def butterworth(inmatrix_b):\n",
        "  high = 1/(50/2)\n",
        "  low = 23/(50/2)\n",
        "\n",
        "  b, a = sp.signal.butter(7, [high,low], btype='bandpass')\n",
        "\n",
        "  for r in emg:\n",
        "    if r in inmatrix_b:\n",
        "      # process EMG signal: filter EMG\n",
        "      emg_filtered = sp.signal.lfilter(b, a, inmatrix_b[[r]])\n",
        "      inmatrix_b[[r]]=emg_filtered\n",
        "  return inmatrix_b"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JxsIrFj9V7SX",
        "colab_type": "text"
      },
      "source": [
        "**3.3. PCA**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7WTmphBWFnc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pca(x_train_c, x_test_c, y_train_c, y_test_c):\n",
        "  pca = PCA(n_components=min(len(x_train_c), len(y_train_c)))\n",
        "  pca.fit(x_train_c)\n",
        "  x_t_train_pca = pca.transform(x_train_c)\n",
        "  x_t_test_pca = pca.transform(x_test_c)\n",
        "\n",
        "  # Plot\n",
        "  #print(\"Normalized matrix\")\n",
        "  #print(pca.explained_variance_ratio_)\n",
        "  #print(pca.singular_values_)\n",
        "  #plt.figure()\n",
        "  #plt.bar(fn[:100], pca.explained_variance_ratio_)\n",
        "  #plt.show()\n",
        "  #plt.bar(fn[:100], pca.singular_values_)\n",
        "  #plt.show()\n",
        "  return x_train_c, x_test_c, y_train_c, y_test_c, x_t_train_pca, x_t_test_pca"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PrXL60g9WO_M",
        "colab_type": "text"
      },
      "source": [
        "**3.4. SVM with Grid Search**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vz0otyHbWRRA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def svm(x_train_s, x_test_s, y_train_s, y_test_s, x_t_train_s, x_t_test_s,combo):\n",
        "    parameters = {'kernel':('linear', 'poly', 'rbf', 'sigmoid'), 'C':[0.1, 1, 10, 100, 1000]}\n",
        "    svc = SVC(max_iter=1000)\n",
        "    #if int(numreps*0.3)<2:\n",
        "    #  nsplit=2\n",
        "    #else:\n",
        "    #  nsplit=int(numreps*0.3)\n",
        "    nested_scores=np.zeros(num_trials)\n",
        "    for t in range(num_trials):\n",
        "      inner_cv=KFold(n_splits=10,shuffle=True,random_state=i)\n",
        "      outer_cv=KFold(n_splits=10,shuffle=True,random_state=i)\n",
        "      #clf=GridSearchCV(svc,parameters,scoring='accuracy',n_jobs=1,cv=min(nsplit,10))\n",
        "      clf=GridSearchCV(svc,parameters,scoring='accuracy',n_jobs=1,cv=outer_cv)\n",
        "      clf.fit(x_t_train_s, y_train_s)\n",
        "      nested_scores=cross_val_score(clf,x_t_test_s,y_test_s,cv=outer_cv)\n",
        "      nested_scores[i]=nested_scores.mean()\n",
        "    #print('score', clf.score(x_t_test_s, y_test_s))\n",
        "    y_pred=clf.predict(x_t_test_s)\n",
        "    #print('pred label', y_pred)\n",
        "    #print('length',len(clf.predict(x_t_test_s)))\n",
        "\n",
        "    # Confusion matrix\n",
        "    #plot_confusion_matrix(clf, x_t_test_s, y_test_s,cmap=plt.cm.Blues)\n",
        "    #plt.title(combo)\n",
        "    #plt.figure(figsize=(50,50))\n",
        "    #plt.show()\n",
        "    bestpar=clf.best_params_\n",
        "    accuracy=nested_scores.mean()\n",
        "    svmresult=classification_report(y_test_s, y_pred)\n",
        "    return svmresult,accuracy, bestpar"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XIoQ54eagg4r",
        "colab_type": "text"
      },
      "source": [
        "# **4. Main code**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKoS0bOpWV7W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "for st in steps:\n",
        "  rownum+=1\n",
        "  columnnum=-1\n",
        "  for pr in products:\n",
        "    columnnum+=1\n",
        "    combo=nsteps[rownum]+' - '+comb[columnnum]\n",
        "    words=set(pr['Word']) # Obtain the target names for the SVM\n",
        "    # First step: set input matrix as regular, normalized or standardized\n",
        "    input_matrix=pr\n",
        "    if st%3==0: # Normalization\n",
        "      input_matrix=norm[columnnum]\n",
        "    if st%5==0: # Standardization\n",
        "      input_matrix=stand[columnnum]\n",
        "    # Second step: apply Butterworth\n",
        "    two_matrix=input_matrix\n",
        "    if st%7==0: # Butterworth\n",
        "      two_matrix=butterworth(input_matrix)\n",
        "    # Third step: split data for later steps\n",
        "    x_train, x_test, y_train, y_test=datasplit(two_matrix)\n",
        "    # Fourth step: apply PCA\n",
        "    x_t_train=x_train\n",
        "    x_t_test=x_test\n",
        "    if st%11==0: # PCA\n",
        "      x_train, x_test, y_train, y_test, x_t_train, x_t_test=pca(x_train, x_test, y_train, y_test)\n",
        "    # Fifth step: apply SVM\n",
        "    if st%13==0: # SVM\n",
        "      svmresults,accuracy,par=svm(x_train, x_test, y_train, y_test, x_t_train, x_t_test,combo)\n",
        "    print('The best parameters for',combo,'are:',par)\n",
        "    fresults[rownum,columnnum]=accuracy*100\n",
        "fresults=pd.DataFrame(fresults,index=nsteps,columns=comb)\n",
        "exec(\"fresults.to_csv(path_or_buf='/content/results_'+str(numreps)+'.csv')\")\n",
        "\"\"\"\n",
        "#stop = timeit.default_timer()\n",
        "#execution_time = stop - start\n",
        "endtime=time.time()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9PwH5XRYrIqd",
        "colab_type": "text"
      },
      "source": [
        "# **5. Results**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqoHNGBxrMHL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "829ac7d0-3076-4b66-aa0e-ba0b23e8125e"
      },
      "source": [
        "#print(fresults)\n",
        "#print('The maximum accuracy for',numreps,'repetitions is',fresults.max().max())\n",
        "print(\"The program executed in \"+str(endtime-starttime))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The program executed in 30.896748065948486\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjJhhkrY_UrQ",
        "colab_type": "text"
      },
      "source": [
        "https://www.studytonight.com/post/calculate-time-taken-by-a-program-to-execute-in-python\n"
      ]
    }
  ]
}